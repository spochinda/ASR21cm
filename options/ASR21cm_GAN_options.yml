# general settings
name: ASR21cm_GAN
model_type: ESRASRGANModel
scale:
num_gpu: auto  # set num_gpu: 0 for cpu mode
manual_seed: 0

# dataset and data loader settings
datasets:
  train:
    name: T21train
    type: Custom21cmDataset
    dataroot_gt: //Users/simonpochinda/Documents/PhD/dataset/varying_IC/T21_cubes/
    dataroot_IC: //Users/simonpochinda/Documents/PhD/dataset/varying_IC/IC_cubes/
    redshifts: [10,]
    IC_seeds: [0,] #,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39]
    Npix: 256
    cut_factor: 2
    scale_max: 4.
    scale_min: 2.
    n_augment: 1
    gt_size: 64
    io_backend:
      type: disk

    # data loader
    use_shuffle: true
    num_worker_per_gpu: 8 # 32
    batch_size_per_gpu: 1
    dataset_enlarge_ratio: 1
    prefetch_mode: ~

  val:
    name: T21val
    type: Custom21cmDataset
    dataroot_gt: //Users/simonpochinda/Documents/PhD/dataset/varying_IC/T21_cubes
    dataroot_IC: //Users/simonpochinda/Documents/PhD/dataset/varying_IC/IC_cubes
    redshifts: [10,]
    IC_seeds: [1,] #,41,42,43,44]
    Npix: 256
    cut_factor: 0
    scale_max: 4.
    scale_min: 2.
    n_augment: 1
    gt_size: 128
    io_backend:
      type: disk

# network structures
network_g:
  type: ArSSR
  ArSSR_opt:
    latent_dim: 32 #  4 # 8 # 32
    use_checkpoint: false
  encoder_opt:
    type: RDN
    num_features: 16 # 8 # consider reducing to 8
    growth_rate: 16 # 2
    num_blocks: 8 # 4
    num_layers: 3 # 4
  # encoder_opt:
  #  type: SongUNet
  #  in_channels: 1
  #  augment_dim: 0
  #  channel_mult: [1,2,]
  #  num_blocks: 4
  #  attn_levels: []
  #  dropout: 0.10
  decoder_opt:
    type: MLP_decoder
    out_dim: 1
    depth: 4 # 4
    width: 128 # 8
    activation: LeakyReLU # LeakyReLU ReLU Tanh
    chunk: false # have to chunk for onebox=false


network_d:
  type: VGGStyleDiscriminator3D
  num_in_ch: 1
  num_feat: 32
  input_size: 64

# path
path:
  pretrain_network_g: ~
  strict_load_g: true
  resume_state: ~

# training settings
train:
  ema_decay: 0.999
  optim_g:
    type: Adam
    lr: !!float 1e-4 # 1e-4
    weight_decay: 0
    betas: [0.9, 0.99]
  optim_d:
    type: Adam
    lr: !!float 1e-6
    weight_decay: 0
    betas: [0.9, 0.99]

  scheduler:
    type: MultiStepLR
    milestones: [5000, 10000, 20000, 30000]
    gamma: 0.5

  total_iter: 40000
  warmup_iter: -1  # no warm up

  # losses
  pixel_opt:
    type: L1Loss
    loss_weight: !!float 1e-2
    reduction: mean
#  perceptual_opt:
#    type: PerceptualLoss
#    layer_weights:
#      'conv5_4': 1  # before relu
#    vgg_type: vgg19
#    use_input_norm: true
#    range_norm: false
#    perceptual_weight: 1.0
#    style_weight: 0
#    criterion: l1
  gan_opt:
    type: GANLoss
    gan_type: vanilla
    real_label_val: 1.0
    fake_label_val: 0.0
    loss_weight: !!float 5e-3

  net_d_iters: 1
  net_d_init_iters: 0
  net_g_iters: 1
  net_g_init_iters: 0

# validation settings
val:
  val_freq: !!float 100
  save_img: true
  pbar: false

  metrics:
    rmse:
      type: calculate_rmse
      better: 'lower'

# logging settings
logger:
  print_freq: 10
  save_checkpoint_freq: !!float 250
  use_tb_logger: true
  wandb:
    project: ~
    resume_id: ~

# dist training settings
dist_params:
  backend: nccl
  port: 29500
